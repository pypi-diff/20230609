# Comparing `tmp/zensols.mimic-1.1.0-py3-none-any.whl.zip` & `tmp/zensols.mimic-1.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,30 @@
-Zip file size: 35255 bytes, number of entries: 28
--rw-rw-r--  2.0 unx      169 b- defN 23-Apr-06 01:33 zensols/mimic/__init__.py
--rw-rw-r--  2.0 unx    15830 b- defN 23-Apr-06 01:33 zensols/mimic/adm.py
--rw-rw-r--  2.0 unx     7178 b- defN 23-Apr-06 01:33 zensols/mimic/app.py
--rw-rw-r--  2.0 unx      624 b- defN 23-Apr-06 01:33 zensols/mimic/cli.py
--rw-rw-r--  2.0 unx     4025 b- defN 23-Apr-06 01:33 zensols/mimic/corpus.py
--rw-rw-r--  2.0 unx    13632 b- defN 23-Apr-06 01:33 zensols/mimic/domain.py
--rw-rw-r--  2.0 unx    25096 b- defN 23-Apr-06 01:33 zensols/mimic/note.py
--rw-rw-r--  2.0 unx     8910 b- defN 23-Apr-06 01:33 zensols/mimic/persist.py
--rw-rw-r--  2.0 unx     5675 b- defN 23-Apr-06 01:33 zensols/mimic/tokenizer.py
--rw-rw-r--  2.0 unx     2093 b- defN 23-Apr-06 01:33 zensols/mimic/resources/app.conf
--rw-rw-r--  2.0 unx     2020 b- defN 23-Apr-06 01:33 zensols/mimic/resources/decorator.conf
--rw-rw-r--  2.0 unx     1330 b- defN 23-Apr-06 01:33 zensols/mimic/resources/default.conf
--rw-rw-r--  2.0 unx      368 b- defN 23-Apr-06 01:33 zensols/mimic/resources/obj.conf
--rw-rw-r--  2.0 unx     1941 b- defN 23-Apr-06 01:33 zensols/mimic/resources/conf/corpus.conf
--rw-rw-r--  2.0 unx     1351 b- defN 23-Apr-06 01:33 zensols/mimic/resources/conf/lang.conf
--rw-rw-r--  2.0 unx     1740 b- defN 23-Apr-06 01:33 zensols/mimic/resources/conf/note.conf
--rw-r--r--  2.0 unx     2327 b- defN 23-Apr-06 01:33 zensols/mimic/resources/conf/persist.conf
--rw-rw-r--  2.0 unx      815 b- defN 23-Apr-06 01:33 zensols/mimic/resources/conf/remove-space.conf
--rw-rw-r--  2.0 unx     1510 b- defN 23-Apr-06 01:33 zensols/mimic/resources/sql/admission.sql
--rw-rw-r--  2.0 unx     1218 b- defN 23-Apr-06 01:33 zensols/mimic/resources/sql/icd.sql
--rw-rw-r--  2.0 unx      161 b- defN 23-Apr-06 01:33 zensols/mimic/resources/sql/medications.sql
--rw-rw-r--  2.0 unx     1894 b- defN 23-Apr-06 01:33 zensols/mimic/resources/sql/note.sql
--rw-rw-r--  2.0 unx      320 b- defN 23-Apr-06 01:33 zensols/mimic/resources/sql/patient.sql
--rw-rw-r--  2.0 unx     2885 b- defN 23-Apr-06 01:33 zensols.mimic-1.1.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-06 01:33 zensols.mimic-1.1.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       45 b- defN 23-Apr-06 01:33 zensols.mimic-1.1.0.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       14 b- defN 23-Apr-06 01:33 zensols.mimic-1.1.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2468 b- defN 23-Apr-06 01:33 zensols.mimic-1.1.0.dist-info/RECORD
-28 files, 105731 bytes uncompressed, 31235 bytes compressed:  70.5%
+Zip file size: 36535 bytes, number of entries: 28
+-rw-rw-r--  2.0 unx      169 b- defN 23-Jun-09 21:49 zensols/mimic/__init__.py
+-rw-rw-r--  2.0 unx    16180 b- defN 23-Jun-09 21:49 zensols/mimic/adm.py
+-rw-rw-r--  2.0 unx     7178 b- defN 23-Jun-09 21:49 zensols/mimic/app.py
+-rw-rw-r--  2.0 unx      624 b- defN 23-Jun-09 21:49 zensols/mimic/cli.py
+-rw-rw-r--  2.0 unx     4966 b- defN 23-Jun-09 21:49 zensols/mimic/corpus.py
+-rw-rw-r--  2.0 unx    13632 b- defN 23-Jun-09 21:49 zensols/mimic/domain.py
+-rw-rw-r--  2.0 unx    28819 b- defN 23-Jun-09 21:49 zensols/mimic/note.py
+-rw-rw-r--  2.0 unx     8910 b- defN 23-Jun-09 21:49 zensols/mimic/persist.py
+-rw-rw-r--  2.0 unx     5544 b- defN 23-Jun-09 21:49 zensols/mimic/tokenizer.py
+-rw-rw-r--  2.0 unx     2093 b- defN 23-Jun-09 21:49 zensols/mimic/resources/app.conf
+-rw-rw-r--  2.0 unx     2020 b- defN 23-Jun-09 21:49 zensols/mimic/resources/decorator.conf
+-rw-rw-r--  2.0 unx     1330 b- defN 23-Jun-09 21:49 zensols/mimic/resources/default.conf
+-rw-rw-r--  2.0 unx      368 b- defN 23-Jun-09 21:49 zensols/mimic/resources/obj.conf
+-rw-rw-r--  2.0 unx     1941 b- defN 23-Jun-09 21:49 zensols/mimic/resources/conf/corpus.conf
+-rw-rw-r--  2.0 unx     1259 b- defN 23-Jun-09 21:49 zensols/mimic/resources/conf/lang.conf
+-rw-rw-r--  2.0 unx     1740 b- defN 23-Jun-09 21:49 zensols/mimic/resources/conf/note.conf
+-rw-r--r--  2.0 unx     2327 b- defN 23-Jun-09 21:49 zensols/mimic/resources/conf/persist.conf
+-rw-rw-r--  2.0 unx      815 b- defN 23-Jun-09 21:49 zensols/mimic/resources/conf/remove-space.conf
+-rw-rw-r--  2.0 unx     1628 b- defN 23-Jun-09 21:49 zensols/mimic/resources/sql/admission.sql
+-rw-rw-r--  2.0 unx     1218 b- defN 23-Jun-09 21:49 zensols/mimic/resources/sql/icd.sql
+-rw-rw-r--  2.0 unx      161 b- defN 23-Jun-09 21:49 zensols/mimic/resources/sql/medications.sql
+-rw-rw-r--  2.0 unx     1936 b- defN 23-Jun-09 21:49 zensols/mimic/resources/sql/note.sql
+-rw-rw-r--  2.0 unx      320 b- defN 23-Jun-09 21:49 zensols/mimic/resources/sql/patient.sql
+-rw-rw-r--  2.0 unx     2885 b- defN 23-Jun-09 21:49 zensols.mimic-1.2.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-09 21:49 zensols.mimic-1.2.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       45 b- defN 23-Jun-09 21:49 zensols.mimic-1.2.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       14 b- defN 23-Jun-09 21:49 zensols.mimic-1.2.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2468 b- defN 23-Jun-09 21:49 zensols.mimic-1.2.0.dist-info/RECORD
+28 files, 110682 bytes uncompressed, 32515 bytes compressed:  70.6%
```

## zipnote {}

```diff
@@ -63,23 +63,23 @@
 
 Filename: zensols/mimic/resources/sql/note.sql
 Comment: 
 
 Filename: zensols/mimic/resources/sql/patient.sql
 Comment: 
 
-Filename: zensols.mimic-1.1.0.dist-info/METADATA
+Filename: zensols.mimic-1.2.0.dist-info/METADATA
 Comment: 
 
-Filename: zensols.mimic-1.1.0.dist-info/WHEEL
+Filename: zensols.mimic-1.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: zensols.mimic-1.1.0.dist-info/entry_points.txt
+Filename: zensols.mimic-1.2.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: zensols.mimic-1.1.0.dist-info/top_level.txt
+Filename: zensols.mimic-1.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: zensols.mimic-1.1.0.dist-info/RECORD
+Filename: zensols.mimic-1.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## zensols/mimic/adm.py

```diff
@@ -27,15 +27,16 @@
 
 logger = logging.getLogger(__name__)
 
 
 @dataclass
 class HospitalAdmission(PersistableContainer, Dictable):
     """Represents data collected by a patient over the course of their hospital
-    admission.
+    admission.  Note: this object keys notes using their ``row_id`` IDs used in
+    the MIMIC dataset as integers and not strings like some note stashes.
 
     """
     _DICTABLE_ATTRIBUTES = 'hadm_id notes'.split()
 
     admission: Admission = field()
     """The admission of the admission."""
 
@@ -52,14 +53,15 @@
     """The notes by the care givers."""
 
     def __post_init__(self):
         super().__init__()
 
     @property
     def hadm_id(self) -> int:
+        """The hospital admission unique identifier."""
         return self.admission.hadm_id
 
     @property
     @persisted('_by_category', transient=True)
     def notes_by_category(self) -> Dict[str, Tuple[Note]]:
         """All notes by :obj:`.Note.category` as keys with the list of
         resepctive notes as a list as values.
@@ -244,14 +246,17 @@
                        include_admission=True,
                        include_patient=True,
                        include_diagnoses=True,
                        include_procedures=True)
         wkwargs.update(kwargs)
         self.write(depth, writer, **wkwargs)
 
+    def keys(self) -> Iterable[int]:
+        return self.notes_by_id.keys()
+
     def __getitem__(self, row_id: int):
         return self.notes_by_id[row_id]
 
     def __contains__(self, row_id: int):
         return row_id in self.notes_by_id
 
     def __iter__(self) -> Iterable[Note]:
@@ -315,14 +320,15 @@
         pp: ProcedurePersister = self.procedure_persister
         adm: Admission = self.admission_persister.get_by_hadm_id(hadm_id)
         pat: Patient = self.patient_persister.get_by_subject_id(adm.subject_id)
         diag: Tuple[Diagnosis] = dp.get_by_hadm_id(hadm_id)
         procds: Tuple[Procedure] = pp.get_by_hadm_id(hadm_id)
         note_events: Tuple[NoteEvent] = self.note_event_persister.\
             get_notes_by_hadm_id(hadm_id)
+        # TODO: move note creation to other stash for mimicsid sec prediction
         notes = tuple(map(self.mimic_note_factory, note_events))
         return self.config_factory.new_instance(
             self.hospital_adm_name, adm, pat, diag, procds, notes)
 
     @persisted('_keys', cache_global=True)
     def keys(self) -> Iterable[str]:
         return tuple(self.admission_persister.get_keys())
```

## zensols/mimic/corpus.py

```diff
@@ -6,17 +6,17 @@
 from dataclasses import dataclass, field
 import logging
 import sys
 from pathlib import Path
 from io import TextIOBase
 from zensols.config import Dictable
 from . import (
-    HospitalAdmission, HospitalAdmissionDbStash,
+    RecordNotFoundError, HospitalAdmission, HospitalAdmissionDbStash,
     PatientPersister, AdmissionPersister, DiagnosisPersister,
-    NoteEventPersister,
+    NoteEventPersister, Note,
 )
 
 logger = logging.getLogger(__name__)
 
 
 @dataclass
 class Corpus(Dictable):
@@ -54,14 +54,37 @@
         # stashes on to the HospitalAdmissionDbStash such as `process_keys`
         self.hospital_adm_stash.delegate_attr = True
 
     def clear(self):
         """Clear the all cached admission and note parses."""
         self.hospital_adm_stash.clear()
 
+    def get_hospital_adm_by_id(self, hadm_id: int) -> HospitalAdmission:
+        """Return a hospital admission by its unique identifier."""
+        return self.hospital_adm_stash[str(hadm_id)]
+
+    def get_hospital_adm_for_note(self, row_id: int) -> HospitalAdmission:
+        """Return an admission that has note ``row_id``.
+
+        :raise: RecordNotFoundError if ``row_id`` is not found in the database
+
+        """
+        hadm_id: int = self.note_event_persister.get_hadm_id(row_id)
+        if hadm_id is None:
+            raise RecordNotFoundError(self, 'hadm_id', hadm_id)
+        return self.hospital_adm_stash[str(hadm_id)]
+
+    def get_note_by_id(self, row_id: int) -> Note:
+        """Return the note (via the hospital admission) for ``row_id``.
+
+        :raise: RecordNotFoundError if ``row_id`` is not found in the database
+
+        """
+        return self.get_hospital_adm_for_note(row_id)[row_id]
+
     def write_note_event_counts(self, subject_id: int, depth: int = 0,
                                 writer: TextIOBase = sys.stdout):
         """Print a list of hospital admissions by count of related notes in
         descending order.
 
         :see: :meth:`.NoteEventPersister.get_note_counts_by_subject_id`
```

## zensols/mimic/note.py

```diff
@@ -5,29 +5,51 @@
 __author__ = 'Paul Landes'
 
 from typing import (
     Dict, Iterable, Set, Tuple, List, Any, Optional, ClassVar, Sequence
 )
 from dataclasses import dataclass, field, fields
 from abc import ABCMeta, abstractmethod
+from enum import Enum, auto
 import sys
 import re
 import collections
+import copy
 import itertools as it
 from itertools import chain
 from io import TextIOBase
 from frozendict import frozendict
 import pandas as pd
 from zensols.config import ConfigFactory, Dictable
 from zensols.persist import PersistableContainer, persisted
 from zensols.nlp import LexicalSpan, FeatureToken, FeatureDocument
 from zensols.nlp.dataframe import FeatureDataFrameFactory
 from . import NoteEvent
 
 
+class SectionAnnotatorType(Enum):
+    """The type of :class:`.Section` annotator for :class:`.Note` instances.
+    The `MedSecId`_ project adds the :obj:`human` and :obj:`model`:
+
+    :see: `MedSecId <https://github.com/plandes/mimicsid>`_
+
+    """
+    NONE = auto()
+    """Default for those without section identifiers."""
+
+    REGULAR_EXPRESSION = auto()
+    """Sections are automatically assigned by regular expressions."""
+
+    HUMAN = auto()
+    """A `MedSecId`_ human annotator."""
+
+    MODEL = auto()
+    """Predictions are provided by a `MedSecId`_ model."""
+
+
 @dataclass
 class ParagraphFactory(object):
     """Splits a document in to constituent paragraphs.
 
     """
     _PARA_REGEX: ClassVar[re.Pattern] = re.compile(r'\n[\s.]*\n')
 
@@ -76,17 +98,17 @@
     keyword in Python.
 
     """
     container: SectionContainer = field(repr=False)
     """The container that has this section."""
 
     header_spans: Tuple[LexicalSpan] = field()
-    """The character start offset of the section, starting with the name and the
-    character offset of the end of the body text.  This is the identifier of
-    the section.
+    """The character offsets of the section headers.  The first is usually the
+    :obj:`name` of the section.  If there are no headers, this is an 0-length
+    tuple.
 
     """
     body_span: LexicalSpan = field()
     """Like :obj:`header_spans` but for the section body.  The body and name do
     not intersect.
 
     """
@@ -112,42 +134,63 @@
         return tuple(map(lambda s: text[s.begin:s.end], self.header_spans))
 
     @property
     def body(self) -> str:
         """The section text."""
         return self.note_text[self.body_span.begin:self.body_span.end]
 
+    def _get_doc(self) -> FeatureDocument:
+        return self.container._get_doc()
+
     @property
     def header_tokens(self) -> Iterable[FeatureToken]:
-        doc: FeatureDocument = self.container._get_doc()
+        doc: FeatureDocument = self._get_doc()
         spans = doc.map_overlapping_tokens(self.header_spans)
         return chain.from_iterable(spans)
 
     @property
     def body_tokens(self) -> Iterable[FeatureToken]:
-        doc: FeatureDocument = self.container._get_doc()
+        doc: FeatureDocument = self._get_doc()
         return doc.get_overlapping_tokens(self.body_span)
 
     @property
+    @persisted('_doc', transient=True)
+    def doc(self) -> FeatureDocument:
+        """A feature document of the section's body text."""
+        return self._narrow_doc(self._get_doc(), self.lexspan, False)
+
+    @property
     @persisted('_body_doc', transient=True)
     def body_doc(self) -> FeatureDocument:
         """A feature document of the body of this section's body text."""
-        return self._get_body_doc()
+        return self._narrow_doc(self._get_doc(), self.body_span)
 
-    def _get_body_doc(self) -> FeatureDocument:
-        doc: FeatureDocument = self._doc_stash[str(self._row_id)]
-        doc = self._narrow_doc(doc)
+    def _narrow_doc(self, doc: FeatureDocument, span: LexicalSpan,
+                    filter_sent: bool = True) -> \
+            FeatureDocument:
+        doc = doc.get_overlapping_document(span, inclusive=False)
+        if filter_sent:
+            sreg: re.Pattern = self._SENT_FILTER_REGEX
+            doc.sents = list(filter(lambda s: sreg.match(s.text) is None,
+                                    doc.sents))
         return doc
 
-    def _narrow_doc(self, doc: FeatureDocument) -> FeatureDocument:
-        sreg: re.Pattern = self._SENT_FILTER_REGEX
-        doc = doc.get_overlapping_document(self.body_span)
-        doc.sents = list(filter(lambda s: sreg.match(s.text) is None,
-                                doc.sents))
-        return doc
+    @property
+    @persisted('_lexspan')
+    def lexspan(self) -> LexicalSpan:
+        """The widest lexical extent of the sections, including headers."""
+        return LexicalSpan.widen(
+            chain.from_iterable(((self.body_span,), self.header_spans)))
+
+    @property
+    def text(self) -> str:
+        """Get the entire text of the section, which includes the headers."""
+        span: LexicalSpan = self.lexspan
+        ntext: str = self.note_text
+        return ntext[span.begin:span.end]
 
     @property
     @persisted('_paragraphs', transient=True)
     def paragraphs(self) -> Tuple[FeatureDocument]:
         """The list of paragraphs, each as as a feature document, of this
         section's body text.
 
@@ -155,14 +198,24 @@
         return tuple(self._paragraph_factory(self))
 
     @property
     def is_empty(self) -> bool:
         """Whether the content of the section is empty."""
         return len(self.body) == 0
 
+    def _copy_resources(self, target: Section):
+        for attr in self._PERSITABLE_TRANSIENT_ATTRIBUTES:
+            setattr(target, attr, getattr(self, attr))
+        target._row_id = self._row_id
+
+    def clone(self) -> Section:
+        clone = copy.copy(self)
+        self._copy_resources(clone)
+        return clone
+
     def write_sentences(self, depth: int = 0, writer: TextIOBase = sys.stdout,
                         container: FeatureDocument = None, limit: int = 0):
         """Write all parsed sentences of the section with respective entities.
 
         """
         def map_ent(tp: Tuple[FeatureToken]):
             """Map a feature token to a readable string."""
@@ -235,15 +288,16 @@
     def __str__(self):
         return f'{self.name} ({self.id}): body_len={len(self.body)}'
 
 
 @dataclass
 class SectionContainer(Dictable, metaclass=ABCMeta):
     """A *note like* container base class that has sections.  Note based classes
-    extend this base class.
+    extend this base class.  Sections in order of their position in the document
+    are produced when using this class as an iterable.
 
     """
     _DICTABLE_ATTRIBUTES: ClassVar[Set[str]] = {'sections'}
 
     @abstractmethod
     def _get_doc(self) -> FeatureDocument:
         """Return the parsed document that represents the text in this
@@ -331,15 +385,15 @@
 
         :param writer: the writer to dump the content of this writable
 
         :param normalize: whether to use the paragraphs' normalized
                           (:obj:~zensols.nlp.TokenContainer.norm`) or text
 
         """
-        for sec in self.sections.values():
+        for sec in self:
             header = ' '.join(sec.headers)
             div_text: str = f'{sec.id}:{sec.name}'
             if len(header) > 0:
                 div_text += f' ({header})'
             self._write_divider(depth, writer, header=div_text)
             if normalize:
                 for i, para in enumerate(sec.paragraphs):
@@ -372,17 +426,14 @@
                 for i, para in enumerate(sec.paragraphs):
                     if i > 0:
                         self._write_empty(writer)
                     self._write_wrap(para.norm, depth, writer)
             elif len(sec.body) > 0:
                 self._write_block(sec.body, depth, writer)
 
-    def __getitem__(self, id: int):
-        return self.sections[id]
-
     def write(self, depth: int = 0, writer: TextIOBase = sys.stdout):
         self.write_human(depth, writer)
 
     def write_full(self, depth: int = 0, writer: TextIOBase = sys.stdout,
                    note_line_limit: int = sys.maxsize,
                    section_line_limit: int = sys.maxsize,
                    section_sent_limit: int = sys.maxsize,
@@ -430,14 +481,20 @@
                           sent_limit=section_sent_limit,
                           include_header=include_section_header)
                 if include_section_divider:
                     self._write_divider(depth + 3, writer)
         if include_note_divider:
             self._write_divider(depth, writer, '=')
 
+    def __getitem__(self, id: int) -> Section:
+        return self.sections[id]
+
+    def __iter__(self) -> Iterable[Section]:
+        return iter(sorted(self.sections.values(), key=lambda s: s.lexspan))
+
 
 @dataclass
 class Note(NoteEvent, SectionContainer):
     """A container class of :class:`.Section` for each section for the
     text in the note events given by the property  :obj:`sections`.
 
     """
@@ -448,28 +505,34 @@
     _DICTABLE_WRITABLE_DESCENDANTS: ClassVar[bool] = True
 
     def _get_sections(self) -> Iterable[Section]:
         sec = Section(0, 'default', self, (), LexicalSpan(0, len(self.text)))
         sec._row_id = self.row_id
         return [sec]
 
-    def _get_annotator(self) -> str:
-        return 'none'
+    @property
+    def section_annotator_type(self) -> SectionAnnotatorType:
+        """A human readable string describing who or what annotated the note."""
+        return self._get_section_annotator_type()
+
+    def _get_section_annotator_type(self) -> SectionAnnotatorType:
+        return SectionAnnotatorType.NONE
 
     def _trans_context_update(self, trans_context: Dict[str, Any]):
         for sec in self.sections.values():
             sec.container = self
             sec._row_id = self.row_id
             sec._doc_stash = trans_context['doc_stash']
             sec._paragraph_factory = trans_context['paragraph_factory']
 
     def write_fields(self, depth: int = 0, writer: TextIOBase = sys.stdout):
+        sat: SectionAnnotatorType = self.section_annotator_type
         self._write_line(f'row_id: {self.row_id}', depth, writer)
         self._write_line(f'category: {self.category}', depth, writer)
-        self._write_line(f'annotator: {self._get_annotator()}', depth, writer)
+        self._write_line(f'annotator: {sat.name.lower()}', depth, writer)
 
     def write_full(self, depth: int = 0, writer: TextIOBase = sys.stdout,
                    note_line_limit: int = sys.maxsize,
                    section_line_limit: int = sys.maxsize,
                    section_sent_limit: int = sys.maxsize,
                    include_section_header: bool = True,
                    sections: Set[str] = None,
@@ -488,25 +551,66 @@
             sections=sections,
             include_fields=include_fields,
             include_note_divider=include_note_divider,
             include_section_divider=include_section_divider)
 
 
 @dataclass
+class GapSectionContainer(SectionContainer):
+    """A container that fills in missing sections of text from a note with
+    additional sections.
+
+    """
+    delegate: Note = field()
+    """The note with the sections to be filled."""
+
+    def _get_doc(self) -> FeatureDocument:
+        return self.delegate._get_doc()
+
+    def _get_sections(self) -> Iterable[Section]:
+        sections: List[Section] = list(
+            map(lambda s: s.clone(), self.delegate.sections.values()))
+        if len(sections) > 0:
+            note_text: str = self.delegate.text
+            gaps: Sequence[LexicalSpan] = LexicalSpan.gaps(
+                spans=map(lambda s: s.lexspan, sections),
+                end=len(note_text))
+            ref_sec: Section = sections[0]
+            sec_cont: SectionContainer = ref_sec.container
+            gap_secs: List[Section] = []
+            for gs in gaps:
+                gsec = Section(
+                    id=-1,
+                    name=None,
+                    container=sec_cont,
+                    header_spans=(),
+                    body_span=gs)
+                ref_sec._copy_resources(gsec)
+                gap_secs.append(gsec)
+            sections.extend(gap_secs)
+            sections.sort(key=lambda s: s.lexspan)
+            sec: Section
+            for sid, sec in enumerate(sections):
+                sec.original_id = sec.id
+                sec.id = sid
+        return sections
+
+
+@dataclass
 class RegexNote(Note, metaclass=ABCMeta):
     """Base class used to collect subclass regular expressions captures and
     create sections from them.
 
     """
     @abstractmethod
     def _get_matches(self, text: str) -> Iterable[re.Match]:
         pass
 
-    def _get_annotator(self) -> str:
-        return 'regular expression'
+    def _get_section_annotator_type(self) -> SectionAnnotatorType:
+        return SectionAnnotatorType.REGULAR_EXPRESSION
 
     def _get_sections(self) -> Iterable[Section]:
         # add to match on most regex's that expect two newlines between sections
         ext_text = self.text + '\n\n'
         matches: Iterable[re.Match] = self._get_matches(ext_text)
         matches = filter(lambda m: (m.end() - m.start() > 0), matches)
         secs = []
```

## zensols/mimic/persist.py

 * *Ordering differences only*

```diff
@@ -60,14 +60,21 @@
         :return: a list of tuples, each in the form (``subject_id``, ``count``)
 
         """
         return self.execute_by_name(
             'select_admission_counts', params=(limit,),
             row_factory='tuple')
 
+    def uniform_sample_hadm_ids(self, limit: int) -> Iterable[int]:
+        """Return a sample from the uniform distribution of admission IDs.
+
+        """
+        return self.execute_by_name(
+            'random_hadm', params=(limit,), row_factory=lambda x: x)
+
 
 @dataclass
 class PatientPersister(DataClassDbPersister):
     """Manages instances of :class:`.Patient`.
 
     """
     def __post_init__(self):
@@ -235,21 +242,14 @@
         :param row_id: the unique IDs of the note events
 
         :return: the hospital admission admissions unique ID ``hadm_id``
 
         """
         return map(self.get_hadm_id, row_ids)
 
-    def uniform_sample_hadm_ids(self, limit: int) -> Iterable[int]:
-        """Return a sample from the uniform distribution of admission IDs.
-
-        """
-        return self.execute_by_name(
-            'random_hadm', params=(limit,), row_factory=lambda x: x)
-
     def get_notes_by_category(self, category: str,
                               limit: int = sys.maxsize) -> Tuple[NoteEvent]:
         """Return notes by what the category to which they belong.
 
         :param category: the category of the note (i.e. ``Radiology``)
 
         :param limit: the limit of notes to return
```

## zensols/mimic/tokenizer.py

```diff
@@ -6,16 +6,15 @@
 from typing import Tuple, Union, Optional, ClassVar, List
 from dataclasses import dataclass, field
 import re
 from frozendict import frozendict
 from spacy.language import Language
 from spacy.lang.char_classes import ALPHA
 from spacy.util import compile_infix_regex
-from spacy.tokens import Token
-from zensols.nlp import Component, SpacyFeatureTokenDecorator, FeatureToken
+from zensols.nlp import Component, FeatureTokenDecorator, FeatureToken
 
 
 @dataclass
 class MimicTokenizerComponent(Component):
     """Modifies the spacCy tokenizer to split on colons (``:``) to capture more
     MIMIC-III pseudo tokens.
 
@@ -39,15 +38,15 @@
         model.tokenizer.infix_finditer = infix_re.finditer
 
     def __hash__(self) -> int:
         return super().__hash__()
 
 
 @dataclass
-class MimicTokenDecorator(SpacyFeatureTokenDecorator):
+class MimicTokenDecorator(FeatureTokenDecorator):
     """Contains the MIMIC-III regular expressions and other patterns to annotate
     and normalized feature tokens.  The class finds pseudo tokens and
     separators (such as a long string of dashes or asterisks).
 
     Attribute :obj:`onto_mapping` is a mapping from the MIMIC symbol in
     :obj:`token_entities` (2nd value in tuple) to Onto Notes 5, which is used as
     the NER symbol in spaCy.
@@ -109,37 +108,37 @@
             if isinstance(pat, str):
                 pat = re.compile(pat)
             repls.append((pat, ent))
             if onto_name is not None:
                 self.onto_mapping[ent] = onto_name
         setattr(self, attr, tuple(repls))
 
-    def decorate(self, spacy_tok: Token, feature_token: FeatureToken):
+    def decorate(self, token: FeatureToken):
         pat: re.Pattern
         ent: str
         oid: str = FeatureToken.NONE
         matched: bool = False
         for pat, ent in self._REGEXES:
-            m: re.Match = pat.match(feature_token.norm)
+            m: re.Match = pat.match(token.norm)
             if m is not None:
                 matched = True
-                setattr(feature_token, self.TOKEN_FEATURE_ID, ent)
+                setattr(token, self.TOKEN_FEATURE_ID, ent)
                 if ent == self.PSEUDO_TOKEN_FEATURE:
-                    feature_token.norm = self.UNKNOWN_ENTITY
+                    token.norm = self.UNKNOWN_ENTITY
                     pseudo_val = m.group(1)
                     for regex, repl in self.token_entities:
                         if regex.match(pseudo_val) is not None:
                             oid = self.onto_mapping.get(repl, FeatureToken.NONE)
-                            feature_token.norm = repl
+                            token.norm = repl
                             break
                 break
         if not matched:
-            setattr(feature_token, self.TOKEN_FEATURE_ID,
+            setattr(token, self.TOKEN_FEATURE_ID,
                     FeatureToken.NONE)
             repl: str
             for pat, repl in self.token_replacements:
-                m: re.Match = pat.match(feature_token.norm)
+                m: re.Match = pat.match(token.norm)
                 if m is not None:
                     matched = True
-                    feature_token.norm = repl
+                    token.norm = repl
                     break
-        setattr(feature_token, self.ONTO_FEATURE_ID, oid)
+        setattr(token, self.ONTO_FEATURE_ID, oid)
```

## zensols/mimic/resources/conf/lang.conf

```diff
@@ -23,14 +23,12 @@
 # decorator.conf for those that turn this specifically to add the `mimic_`
 # entity
 #
 # override to add the MIMIC corpus handling components and remove empty
 # sentences created by two spaces and other whitespace between sentences
 [doc_parser]
 components = instance: list: mimic_component, mimic_tokenizer_component
-remove_empty_sentences = True
 
 # override to mirror overrides in doc_parser and use the default doc_parser
 # token feature IDs in the default (compare to decorator.conf)
 [mednlp_doc_parser]
 components = ${doc_parser:components}
-remove_empty_sentences = ${doc_parser:remove_empty_sentences}
```

## zensols/mimic/resources/sql/admission.sql

```diff
@@ -54,7 +54,13 @@
 	       a.diagnosis in (
 	  select distinct(diagnosis)
 	      from admissions
 	      where diagnosis like '%HEART%' or diagnosis like '%CARDIAC%');
 
 -- test
 select * from admissions where subject_id=13033;
+
+-- name=random_hadm
+select hadm_id from noteevents
+    where hadm_id is not null
+    order by random()
+    limit %s;
```

## zensols/mimic/resources/sql/note.sql

```diff
@@ -52,14 +52,21 @@
           hadm_id is not null
     order by description
     limit %s;
 
 -- name=select_note_count
 select count(*) from noteevents where hadm_id = %s;
 
+-- name=select_note_counts
+select hadm_id, count(hadm_id) as cnt
+    from noteevents
+    where hadm_id is not null
+    group by hadm_id
+    order by cnt desc;
+
 -- name=select_note_count_by_subject_id
 select hadm_id, count(hadm_id) as cnt
     from noteevents
     where subject_id = %s and hadm_id is not null
     group by hadm_id
     order by cnt desc;
 
@@ -67,13 +74,7 @@
 select count(*) from noteevents;
 
 -- name=missing_hadm_count
 select count(*) from noteevents where hadm_id is null;
 
 -- name=total_count
 select count(*) from noteevents;
-
--- name=random_hadm
-select hadm_id from noteevents
-    where hadm_id is not null
-    order by random()
-    limit %s;
```

## Comparing `zensols.mimic-1.1.0.dist-info/METADATA` & `zensols.mimic-1.2.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 Metadata-Version: 2.1
 Name: zensols.mimic
-Version: 1.1.0
+Version: 1.2.0
 Summary: MIMIC III Corpus Parsing
 Home-page: https://github.com/plandes/mimic
-Download-URL: https://github.com/plandes/mimic/releases/download/v1.1.0/zensols.mimic-1.1.0-py3-none-any.whl
+Download-URL: https://github.com/plandes/mimic/releases/download/v1.2.0/zensols.mimic-1.2.0-py3-none-any.whl
 Author: Paul Landes
 Author-email: landes@mailc.net
 Keywords: tooling
 Description-Content-Type: text/markdown
 Requires-Dist: Pillow (~=9.2.0)
-Requires-Dist: zensols.mednlp (~=1.1.0)
+Requires-Dist: zensols.mednlp (~=1.2.0)
 Requires-Dist: zensols.dbpg (~=1.0.0)
 
 # MIMIC III Corpus Parsing
 
 [![PyPI][pypi-badge]][pypi-link]
 [![Python 3.9][python39-badge]][python39-link]
 [![Python 3.10][python310-badge]][python310-link]
```

## Comparing `zensols.mimic-1.1.0.dist-info/RECORD` & `zensols.mimic-1.2.0.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 zensols/mimic/__init__.py,sha256=aBhQImLOYucT3EaPcbp0PX5uy5W4Hm_jXQWE3WulKck,169
-zensols/mimic/adm.py,sha256=HaOCnA6suaykkJprjleXbzeE9OYh8aLzbqX6e22zpgQ,15830
+zensols/mimic/adm.py,sha256=fGIJPvebMzrlE8Bu7Wup6JGQ7z0ibxug1SBD5zm5bys,16180
 zensols/mimic/app.py,sha256=D5_Wk6Vy97THn8ByU6tearhJ0F4fL6_grJs-seeE9eM,7178
 zensols/mimic/cli.py,sha256=qK7VKpupSOltxNXmBYRTCRY08Woj-KGxLYVNALNtO5A,624
-zensols/mimic/corpus.py,sha256=3EzRKFLJxNhjvXhBloV9ma5Yr73CjV3yV_MM0v29VIs,4025
+zensols/mimic/corpus.py,sha256=Xy6Bo9id127EKse8K6x6jnF0RHz6WoLcRnHD59x6_6U,4966
 zensols/mimic/domain.py,sha256=HE4WAMU0i2AOlcEJ-ZQjutzK5OMrjSnyyaOXCd4L6EM,13632
-zensols/mimic/note.py,sha256=2lUA9a0LEfjr1qRUiXFCDSn10Zaq8c0jyWAJDNKqhbI,25096
-zensols/mimic/persist.py,sha256=akDOlDRuBfl3GERUhUmw5_WSLaLwqmDJBbiAwtGY568,8910
-zensols/mimic/tokenizer.py,sha256=0Lj-WapJQw3FT84r9v5S-t5TPqgIoEpse_dCeSoZd5Y,5675
+zensols/mimic/note.py,sha256=G9bgbGhXAvMYlqZKNEAWYP1jWnNlbJuUIdYGg4lCR_0,28819
+zensols/mimic/persist.py,sha256=ffuXth97S0EJlannjs92TA9hbusmAxWpLg7CSzp9W9Q,8910
+zensols/mimic/tokenizer.py,sha256=WSZIcpMfkjAK24-DzPlirHgW6q0MFHll34wFLYLvoIw,5544
 zensols/mimic/resources/app.conf,sha256=_oVERqtRB4AUnPN52M5Arqsp5fFK_Jpj9-e4iYqt-R0,2093
 zensols/mimic/resources/decorator.conf,sha256=47fwgAJL_CYPBfVsgcIeGXNjNB26kUuRBermoZlt3T4,2020
 zensols/mimic/resources/default.conf,sha256=TZZj6fw4vFBmXbw3DHZxTIYsEMR9ccIbF9BIZ7slCRo,1330
 zensols/mimic/resources/obj.conf,sha256=dTNl8O7iaWPNJfRYWyGkDA1ES2EZcKuNIOxH_dVAMsM,368
 zensols/mimic/resources/conf/corpus.conf,sha256=JPb2zQMZgfULtCz8xko-D9gP_oH7ohmnNLwJ4OijJj4,1941
-zensols/mimic/resources/conf/lang.conf,sha256=6fO9xYpAbykyHMhTOPkJEVbwOdKwn9khyYVSk8HljmY,1351
+zensols/mimic/resources/conf/lang.conf,sha256=gDef-6x84xK6epRk1ZBs0dNk9rn9sy2r9mYXYk9PQWE,1259
 zensols/mimic/resources/conf/note.conf,sha256=_jTc3qNiqtvUqfFVGVT-T5U7CZUAh0Vr8m_gjoZC6DQ,1740
 zensols/mimic/resources/conf/persist.conf,sha256=PGhenWNwEL1eV8boZFfvmD2sxEjOAaHy6D0OLafeJ_w,2327
 zensols/mimic/resources/conf/remove-space.conf,sha256=B_ofTZOQpa_qhpS5LT-W3tQ8nqbful-RSLOgM5Y7z-I,815
-zensols/mimic/resources/sql/admission.sql,sha256=cYrLEXRhX6CY7c5RMk2rFB50_EGDBuX0hbfriONU1lI,1510
+zensols/mimic/resources/sql/admission.sql,sha256=b8HpDYhD7gLf66baiTYOZnUEX3I41qDo8gJBnqBb33c,1628
 zensols/mimic/resources/sql/icd.sql,sha256=pV8p_GATzWqbh3BRvhrX9rLSNOPjyASdWRdKGNCs-GQ,1218
 zensols/mimic/resources/sql/medications.sql,sha256=8Ebgt_IF1rXqLbbbmeQcJg1oUMHYpU4KTMod6fubvFA,161
-zensols/mimic/resources/sql/note.sql,sha256=PORLZSQ31XalPlXUIPIUaNyvScjjwwDipyikUfdfZsY,1894
+zensols/mimic/resources/sql/note.sql,sha256=bvY8sorDK3W90FQSUMT4reQRIiTojUUZf35GFf8eNxE,1936
 zensols/mimic/resources/sql/patient.sql,sha256=x0bm411rPMJJxp6zujnaMLNP2EAJQbgVQ4vm7DiRGWg,320
-zensols.mimic-1.1.0.dist-info/METADATA,sha256=iu1O57MvEvJKY62YIbS4f7ZZSLHWX9h15w-niPlx7y4,2885
-zensols.mimic-1.1.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-zensols.mimic-1.1.0.dist-info/entry_points.txt,sha256=9uACXuaRA0PkUS5F1T48QWcfiIoOhdnJu_VheNlRuHg,45
-zensols.mimic-1.1.0.dist-info/top_level.txt,sha256=IUsP4rDMhar7GriBPPNxw1jm5KDq136q96gT-GWk-cI,14
-zensols.mimic-1.1.0.dist-info/RECORD,,
+zensols.mimic-1.2.0.dist-info/METADATA,sha256=5VIMz-tHOnVdBzFuEMNu89IPZJpsZXyb50tyZAdXeTQ,2885
+zensols.mimic-1.2.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+zensols.mimic-1.2.0.dist-info/entry_points.txt,sha256=9uACXuaRA0PkUS5F1T48QWcfiIoOhdnJu_VheNlRuHg,45
+zensols.mimic-1.2.0.dist-info/top_level.txt,sha256=IUsP4rDMhar7GriBPPNxw1jm5KDq136q96gT-GWk-cI,14
+zensols.mimic-1.2.0.dist-info/RECORD,,
```

